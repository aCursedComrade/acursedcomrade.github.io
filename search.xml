<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Heading into 2024...</title>
    <url>/2023/12/into-2024/</url>
    <content><![CDATA[Oh boy, its almost 2024 and this blog has been dry for a while. So I want to leave my thoughts here before the new year, looking back at what happened and what I hope for the future.


2023 has been a good year. Not really an eventful one for my introverted self but it was good nonetheless. Got myself occupied as an undergraduate, learning new things and getting those darn coursework done on time. I am also thankful for the new peers I met who share similar niches with me, they are a joy to work with. And of course, continued to break and learn cyber stuff as usual. Its cool to have your own domain and some infrastructure to spin up stuff that greatly helps your day-to-day work. Makes you feel unstoppable.
As for what I have planned for the next year, tackling the bachelors is on the priority list. Working on my final research project as well at the time of writing. Then its about moving in to the field, getting that first foothold somewhere nice. And as usual, keep hacking away and learning new things.
Even though the little me did not have much of an eventful year, the world certainly did. We saw a lot of ups and downs, wins and losses and then peace and chaos. Looking back at all that happened, what I want to say is that please be excellent to each other, help out when you can because it can make a difference. And finally, stick to your goals. Its OK to get distracted once in a while but stay positive and remember what you are working for.
With that, I wish everyone a happy new year! Stay safe and keep kicking butt o7
]]></content>
      <tags>
        <tag>personal</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World!</title>
    <url>/2022/12/hello/</url>
    <content><![CDATA[Hello world! Welcome to my little corner of the inter-webs.


Hey there!This is my shot at making a blog and writing about stuff. You can expect me to write about tech stuff, cybersecurity (when I am a professional ‘wink’), games ??? Or anything else that I may find interesting.
And that’s about it for this post. You can take a look at the about page for more information about me. Thanks for reading!

]]></content>
      <tags>
        <tag>personal</tag>
      </tags>
  </entry>
  <entry>
    <title>Off to 2025</title>
    <url>/2024/12/into-2025/</url>
    <content><![CDATA[Well… this blog has been dry for a real long time huh… &gt;_&gt; Anyways, it’s time to leave 2024 behind and jump head first into 2025 which also means it’s time for me to “step out from the shadows” and reflect on what happened this year and what I expect in the future. I got few things to share since my last yearly update.


First of all, I graduated from my computer security bachelors with first-class honors! Yippeeee! The past 3 years (+1 with foundation program) has been a rollercoaster. From actually understanding programming and deciding to follow computer security (and networks) oriented discipline, I can see that I have traveled far since 2019. Looking back at my younger, bratty self who tried to run Metasploit or use a pirated version of Cobalt Strike against my family’s devices, I feel both embarassed and proud seeing that I have deeper, useful knowledge and experience in information security that I can use to help my peers and people around me with and contribute to the digital space in various ways. I am thankful for my parents, professionals in and out of academics, and peers (new and old alike) who supported me during this period. I wish all my graduate peers good luck with their next step. I do hope we can keep in touch at times in the future.
Speaking of bachelors, I completed my final year research project sucessfully, too. It is a framework for “sandboxing” (isolating&#x2F;limiting) running applications on Microsoft Windows with the objective of improving personal privacy and operational security. This does not really include novel techniques that are not known yet but its more of a demonstration of how one can impose controls and security measures on running applications. This has been largely inspired by and works similar to Sandboxie (for Windows) and firejail (for Linux) solutions which I use on a day-to-day basis as well. You can view the source code for this research&#x2F;framework on my GitHub repo (aCursedComrade&#x2F;sandbox-research). NOTE: This is not a complete product fit for daily use, it will remain as a toy for myself to learn about application security and operating system internal in its time, possibly.
Other than that, I had the pleasure of organizing events with ISACA student chapter of my university, taught juniors and peers on different technical matters, did a few audits and vulnerability discolsures as an independant security researcher, started working on professional certifications, got back in touch with old friends and started hitting the gym for those gains. Overrall, it has been a nice year for me. As of writing this post, I am working on getting hired into the field, stabilizing myself and learning to be independant. It does suck to leave my little cave and face the horrors of adulthood but oh well, I got places to be in.
With all that said, I wish a happy new year for all of you who come across this post. Stay safe, be kind, and follow your goals into 2025 o7
]]></content>
      <tags>
        <tag>personal</tag>
      </tags>
  </entry>
  <entry>
    <title>&quot;/proc&quot; file system | Enumerating for a foothold</title>
    <url>/2023/03/proc-enumeration/</url>
    <content><![CDATA[The /proc filesystem is a unique location in a Linux system which holds runtime information of the system. Let’s look at why does it exist and how can a malicious actor can leverage it for enumeration.


What is “&#x2F;proc”?The proc file system, which usually lies in /proc directory of a Linux system, contains information about the runtime of the system and all processes on the system. This information is stored in the form of files or file-like objects which can be read from using simple text readers such cat or grep and can be modified by high-privileged users and processes for different purposes.
If let’s say a vulnerability like LFI (Local File Inclusion), command injection or similar exists on a web app, which provides an attacker with read access on the target system. This exposes the /proc file system and most likely sensitive information alongside of it.
A little scenarioThroughout this post, I will be using a small python Flask app that is deliberately vulnerable to an LFI to demonstrate the attack vector. The code for the web app is given below, make sure to run it in a contained environment:
from flask import Flask, requestapp = Flask(__name__)@app.route(&#x27;/&#x27;)def index():  return &#x27;Hello there!\n&#x27;@app.route(&#x27;/read&#x27;)def read():  file = request.args.get(&#x27;fn&#x27;)  with open(f&#x27;/tmp/&#123;file&#125;&#x27;, &#x27;rb&#x27;) as f: # Classic LFI    data = f.read()    return dataif __name__ == &#x27;__main__&#x27;:  app.run()

If you haven’t already installed the Flask library, you can do so by executing the command:
pip install Flask

For demonstration, I’m using the export command to create a few environment variables before we run the application. To do this and run the script, we can execute the following:
export SOME_VAR=&quot;aVariableHere&quot; \SECRET=&quot;YouShouldntBeReadingThis&quot; \VERSION=&quot;6.9.0&quot; \DB_URL=&#x27;mysql://dbuser:P@$$w0rd@localhost/webapp&#x27;; flask --app app run

Make sure to execute the command in the same directory as the script. If executed successfully, our vulnerable web app should be listening for new connections.


The attack beginsFirst things first, let’s confirm the LFI by querying the classic /etc/passwd. If we look at the source code again, the app is trying to read from /tmp with the filename passed directly in to the expression without any sanitation. We only need a single .. operator to access the file system root. So our malicious query will be:
curl &#x27;localhost:5000/read?fn=../etc/passwd&#x27;



Great! (or not so great wink) This means that we can now read all files in the system which can be read by the system account running the web app. An attacker can now try to read various configuration files that are presumably on default locations (on the file system) or other files of interest and gather as much as information to gain a foothold.
“&#x2F;proc” structure
You can break down the entries into two major categories. One is kernel (or system) information and the other is process specific information.
The numbered directories you see are made for each process, thus containing process information. The number represents the process ID (PID) of each individual process.
The remaining directories and file-like objects contains kernel information (but there are 4 interesting exceptions which will be discussed below).
Another interesting fact is that /proc occupies no disk space at all (or at least a very minimal amount), the kernel (or the system) generates the necessary information dynamically when programs access specific entries within /proc.
Except for a few entries, the contents of /proc are globally readable. But as an attacker, we only have to look at a few interesting entries.



This post will go over some entries briefly. You can read the complete documentation for the /proc file system and its entries from the Linux documentation or man pages (see references) in your own terminal. More links are available at the end of the post.


In this scenario, we are using an LFI vulnerability to read files off the system. We can read entries (files or file-like objects) in /proc and in other parts of the file system, but we cannot read directories which is the expected behavior. However, a capable attacker can automate a brute-force attack with a list of possible file&#x2F;directory names to discover files in the file system.


Kernel information
/proc/cpuinfo
Returns information regarding individual CPU cores available to the system. (Response can be quite long depending on the number of cores)






/proc/meminfo
Returns information about the system memory. This includes total memory, used memory, free memory, etc.






/proc/version
Returns the kernel version information.






/proc/partitions
Returns the partition table known to the system.





As mentioned in &#x2F;proc structure, there are few interesting links that are available within /proc. Simply, they are magical links that automatically points to the process directory of the current process. They are listed below:

/proc/self

This is a magical link that automatically points to the relevant /proc/&lt;PID&gt;/ directories of the processes that are currently accessing the entry. This was introduced as a convenient way of accessing own process information. Thus, it can be easily used in attacks such as LFI to quickly expose information about the current process without having to know the PID.


/proc/mounts

Like /proc/self, this link points to the /proc/&lt;PID&gt;/mounts entry of the own process. This contains information about the file system mounts that are accessible by the process (Refer /proc/mounts in man pages). This can include network shares that are mounted on the system.
For example, below you can see a mount that is created by KDE Connect that is exposing some folders in my android device. In the next screenshot, I’m accessing the Documents/message.txt within that share which is an example of information disclosure.








/proc/net/
Like /proc/mounts, this link points to the /proc/&lt;PID&gt;/net/ directory of the own process. The entries within this directory hold different kinds of information about the networking stack that is accessible by the process (Refer /proc/net in man pages).
For example, the arp entry holds the ARP cache of the system which can be used to discover internal hosts of the network and interface names that are useful to know in some cases. tcp and udp entries have relevant connections that are established or listening on the system (in hex format).






/proc/threads-self
Like the above magic links, this points to the relevant /proc/&lt;PID&gt;/task/&lt;TID&gt;/ (process thread) directory of the own process, if it is being accessed by a thread. The TID here is similar to a PID and threads are accessible via /proc/&lt;TID&gt; as well. However, threads are different from processes in computing.





Process informationIn this scenario, we can use the /proc/self/ link to expose information about the web app process without guessing the PID. But it is possible to brute-force PID to find processes of interest.



/proc/&lt;PID&gt;/comm &amp; /proc/&lt;PID&gt;/cmdline
comm and cmdline hold the base name of the command and the complete command (with arguments) used to execute the command respectively. cmdline will spit out the command with the spaces in between arguments replaced by a null byte ‘\0’. We can pass this through a replace function to restore the spaces. What’s important here is that the command line arguments can contain passwords (This is bad practice).






/proc/&lt;PID&gt;/status
This entry contains an array of different kinds of information. Name, Pid, PPid (Parent PID), Uid (Effective user ID), Gid (Effective group ID) and Groups (Groups the process belongs to) are some important fields out of it for enumeration.






/proc/&lt;PID&gt;/environ
This is the most important one in my opinion. This holds the initial environment variables that was used to execute the process with. By initial, it means that if any changes happen to these variables during the process lifetime, it won’t be reflected here.
Often in production and in development, environment variables are used to hold configuration information and usually contain sensitive information like secret keys, authentication tokens, database credentials, etc.
For example, here we’ve dumped our dummy variables that we set up earlier (the newlines ‘\n’ are replaces by null bytes ‘\0’ here as well) (I have also truncated the output to remove any unnecessary variables from my ZSH config).






/proc/&lt;PID&gt;/cwd/
This is a symbolic link that points to the current working directory of the process. Can sometimes be used as a shortcut in the context of the web app path on the file system. The PWD variable can be extracted from /proc/&lt;PID&gt;/environ to figure out what is the current working directory.








/proc/&lt;PID&gt;/exe
This entry points directly to the executable command that is used run the command. Reading this will output raw binary data. Useful when you are dealing with custom standalone binaries during challenges, and you want to extract them for analysis and reversing.






/proc/&lt;PID&gt;/fd/
This directory contains symbolic links to each file that is open in the process, named using numbers (Numbers correlate to the entries in the fdinfo/ directory). Except the first three; 0, 1, 2 which are stdin, stdout and stderr respectively, files can be queried to view thier contents which may contain important information. Sometimes it can be used to execute code in the context of the web app (see references).





Concluding thoughtsThat’s about it for my first blog post :) This post covered a few interesting locations in the Linux /proc file system that an attacker with some read access on the system during initial compromise or even during post exploitation phase can enumerate to uncover information. You can refer the links in the below sections for more information about the topic.
But this is a small part of an attack chain. Depending on the context of the scenario, an attacker will think outside box to carry out the attack chain and compromise a system. YOU should think out of the box too.
Thank you for reading o7


Extra reading
Linux enumeration with read access only
Directory Traversal, File Inclusion, and The Proc File System

References
The Linux Documentation Project
man7 on the web
LFI to RCE via &#x2F;proc&#x2F;*&#x2F;fd

]]></content>
      <tags>
        <tag>linux</tag>
        <tag>ctf</tag>
        <tag>attack</tag>
      </tags>
  </entry>
  <entry>
    <title>Pocket home lab | Setting up remote access to your home lab</title>
    <url>/2023/06/remote-lab-access/</url>
    <content><![CDATA[Remote access is a crucial aspect to consider when you setup your own infrastructure. You could have it sitting on the “edge” and be able to directly talk to it or use a secure VPN to have controlled access. Here, I have written about my experience with for setting remote access to my home lab with ZeroTier and possible alternatives ways one can approach the same scenario.


Home lab on the goIt is a common habit to have your own home lab among many professionals and enthusiasts in the IT field. Whether it is about hosting your content to serve the internet or tinkering with networks and applications, a home lab can be your workplace or your playground. There are different approaches to implementing a home lab depending on the resources available. Cloud platforms can be effortlessly used to create infrastructure virtually but costs increase relative to scale. Alternatively one can use accessible hardware to set up in an available physical location.
Cloud platforms provide easy methods to expose and define access controls to your assets that sits on the “edge”. When working with your own hardware however, you need to manually integrate your infrastructure with services like site-to-site VPNs or SD-WANs to achieve this goal. In addition, some external factors may affect your implementation. Such as Carrier-grade NAT (CGNAT) used by ISPs which doesn’t allow peer-to-peer connections. It is possible to allocate a public IP for your infrastructure, but there are alternative technologies that can help you to circumvent limitations of CGNAT.
This blog is about interconnecting the infrastructure, I won’t be covering how to start your own home lab from scratch. However, there are lots of resources to get started out there already. Also, huge kudos to @0xBEN for his resources that helped me get started with mine.


Connecting the nodesMy home lab layout is based on @0xBEN’s Proxmox VE guide (see references) which was used as the foundation for building my home lab, and therefore I will be quoting some content from his blog with his permission to demonstrate the network layout. Before continuing further, below diagram shows our home lab layout:


As of writing this blog post, my home lab layout is similar to what’s shown in the diagram except for the absence Wazuh SIEM and dedicated OpenVPN&#x2F;WireGuard VMs. I added my own changes which I think is more suitable or interesting. There’s so many rabbit holes to go down and experiment on :D


My goal is simple, I need to be able to talk with the following 3 hosts in order to properly work with my home lab:

Proxmox hypervisor: To manage the virtual infrastructure.
Virtual pfSense firewall: In addition to firewall services, this is also used as a OpenVPN server to access VMs on vmbr1 (Security) vSwitch. Has access to home LAN.
A utility VM: Running bare-bones Arch Linux, my plan is to use this VM to host certain services that I may find useful (discussed later in this post). Has access to home LAN.

0xBEN’s guide demonstrate how dynamic DNS can be used to communicate with the lab remotely. But this was not the case for me due to CGNAT limitations on my ISP connection. Upon looking for alternatives, these are some solutions that I found popular (in no particular order) that I can use:

ZeroTier
Tailscale
Defined Networking which uses Nebula and manages backbone infrastructure for individuals&#x2F;organizations.
Netmaker

These services have the same use case, being able to connect internal or non-internet-facing hosts over a virtual network for remote access, with each having a few different features with different underlying spec. These services provide a decent pricing plan with a generous free tier for individual and some services or their underlying frameworks are publicly available and can be self-hosted by capable individuals.
One more important point to highlight is that these services provide different synergies with other services&#x2F;devices as well. For example, pfSense officially support Tailscale to bridge “sites” (subnets) together and likewise MikroTik’s RouterOS supports ZeroTier integration. This can help bridge private networks quick and easily without having to configure intermediate routing&#x2F;service in between. However, for my first run I decided to use ZeroTier, and it has been pretty simple to get started and work with.
ZeroTierZeroTier combines the capabilities of VPN and SD-WAN to connect all kinds of end user devices to a single virtualized network. The virtual interface created by ZeroTier makes it feel like a regular LAN network where you can manage routes, assign IPs, define flow rules, etc. while providing end-to-end encryption to all traffic.
It is also an open source project (some actions falls under their business license) and the relay server implementation is publicly available for anyone to self-host their own instance. They also provide a development SDK (a socket library) in a few different programming languages that can be used create and connect embedded applications and systems over the virtual network.
If you want to read more and get started with deployment, make sure to read their documentation and knowledge base for guides and troubleshooting. Now, let’s go over the steps you need to set up a ZeroTier network.

After signing up for an account, you will land on your account dashboard. This page gives you an overview of your active networks and total number of nodes&#x2F;hosts connected. Clicking “Create a Network” will create a new network entry on the dashboard with a random name. To continue, click on the new record to open the network configuration page.




There are subsections for help regarding each option you see in this configuration page. Make sure to refer that if you have any doubts about a component.
The basic settings section can be used to customize the name, description and the level of access control of your network. Private mode creates an additional authorization step which has to be approved by a network administrator before a node is allowed to communicate with the network.




The advanced settings section contains network related options that you can configure according to your needs.
Managed Routes dialogue can be used to manually add routes through the connected nodes. Additional configuration on the target node is required to make this work.
IPv4 Auto Assign dialogue lets you define a IPv4 private address range (RFC 1918) that will be used to automatically allocated addresses to connecting nodes. You may want to double-check your allocation with your LAN or other networks that might overlap and cause issues with routing.
IPv6 Auto Assign dialogue works the same as IPv4.
Multicast dialogue lets you configure multicast recipient limit and enable broadcast within the network.
DNS dialogue lets you define an internal domain for the network and assign a DNS server node.
Manually Add Member dialogue lets you authenticate a node before it joins a network (or to unban a previously banned node).








Heading over to Members section after configuring your settings, you will see a message about adding new members. You should now download and install the client daemon on to the devices you need to connect to the network (You will need administrative privileges when working with ZeroTier client). Assuming you are on a Linux distribution, you can try the below command on your terminal to test the CLI tool:

# To print help textsudo zerotier-cli help

# To view your client infosudo zerotier-cli info

The client info command returns your client ID and service status, client ID (or member ID) is used to uniquely identify nodes when adding&#x2F;removing from the network. We should now join our node to the virtual network with the network ID that is shown in the dashboard or in the network management page.

# To join a networksudo zerotier-cli join NETWORK_ID

# To list active network statussudo zerotier-cli listnetworks

Assuming you have chosen to keep the network private in the configuration stage, the status of the previous command will be “ACCESS DENIED” because you need to approve the node before it can start communicating over the network. Head over to the Members section we previously left before, you should now see a new record with the client ID of the node you are working with. Check the box on the “Auth” column to approve the node.




If everything went accordingly, your node will be assigned an IP address from the range you previously configured. Use the listnetwork command in the CLI tool to verify. The service also configures a virtual network interface for the node which you can see with ip a command.

You should now repeat above steps for the remaining hosts that you need on the network. The client daemon makes sure that every time a host reboots, the virtual interface will be brought back up again. All you need is to be able to connect and talk to ZeroTier or your own relay server over the internet, then you can just treat it like a usual LAN connection.
Virtual network overview

Going back to my home lab setup, I connected my Proxmox node, utility VM, my personal laptop and my mobile to the network. The remaining node is the pfSense firewall but the reason I cannot connect it is that it may cause issues with the firewall config and my lack of knowledge on the BSD ecosystem. Even though I have listed about how to forward these internal services, another approach would be to have the firewall connected directly connected with our SD-WAN solution, so we can directly bridge internal subnets via the firewall without any intermediate forwarding or other solutions (I included a few examples in a previous section).


I initially used the Proxmox node as a proxy (by using the ssh -R option to create a reverse socks proxy) to access pfSense web panel and its OpenVPN server. It is a working alternative, but the next section covers how forward proxies can be used AND how we can assign a verifiable domain with the help of certain project.
A forwarding proxyAt this point, my attention went towards Nginx as this is a perfect scenario to set it up on the utility VM. It can act as a reverse proxy to serve internal services or forward TCP&#x2F;UDP connections to internal services.
This is when I found a nice video that covers Nginx proxy manager project which can streamline the usage of Nginx and easily assign a domain name with verifiable security (SSL) to sites even if they are not exposed to the internet. I recommend watching the video for detailed steps, and my changes to its configuration is listed below.


Nginx Proxy Manager
For the domain, I have selected comradenet.duckdns.org (that’s a pretty long domain name) and pointed the record at the ZeroTier assigned address 172.27.10.11 of the utility VM.
After setting up docker and docker-compose on the VM, I took the docker-compose file in the quick setup page and added an extra mapping to port 1194 which is the default port for OpenVPN servers.

version: &#x27;3.8&#x27;services:  nginxproxymanager:    image: &#x27;jc21/nginx-proxy-manager:latest&#x27;    restart: unless-stopped    ports:      - &#x27;80:80&#x27;      - &#x27;81:81&#x27;      - &#x27;443:443&#x27;      - &#x27;1194:1194&#x27;    volumes:      - ./data:/data      - ./letsencrypt:/etc/letsencrypt

After spinning up the container and going through the initial login setup, I created an SSL certificate as described in the video.




Moving on to proxy host configuration, the process is same as seen in the video. After defining two subdomains for Proxmox and pfSense, the destination is pointed towards their LAN addresses. One additional detail is that we need to enable Websocket support on both proxy records for the web panels to work correctly (This is the case for Proxmox and pfSense web panels, other web services may differ).




And finally, I defined a stream record to forward all incoming traffic on port 1194 to the same port on pfSense firewall via the LAN. With that, I just need to define the target server on the OpenVPN client config as the utility VM and the proxy will forward the traffic to pfSense server. TCP forwarding is selected as the OpenVPN server is configured to use TCP instead of UDP.



And that’s the proxy manager configuration for my environment. You may need to define additional port mappings depending on what you are trying to set up forwarding. You are free to stop and scrap the container when you want to modify port mappings as all the data is stored in mounts as defined in the docker-compose file.
Make sure to properly organize mount folders on your docker host, so your configuration is not lost.


Proxy in actionNow I can easily access my web panels by using a nice little URL on my browser and join my internal VPN to play around with my cyber playground as long as I am connected to my ZeroTier network.




Nginx proxy manager has been pretty helpful to me as a beginner. The GUI has more options available inline with what Nginx has to offer, but one might need to manually configure their Nginx instance to fine tune all the options it has to offer.
Concluding thoughtsAnd that’s about it for this home lab adventure. This has been a nice learning experience for me when it comes to network implementation and technologies behind them. I am planning try out more services as listed in this post to come up with a better network design that is easy to use and maintain. The industry certainly has much more to offer, and this post only covered a few of them.
I would like to thank @0xBEN again for his awesome resources that got me interested in tinkering as well. And thank you for reading my post, hope you enjoyed and possibly gained something from my post.
References
Proxmox VE 7: Converting a Laptop into a Bare Metal Server by 0xBEN
Setting up a reverse proxy and SSL for your home lab

]]></content>
      <tags>
        <tag>homelab</tag>
        <tag>networking</tag>
      </tags>
  </entry>
</search>
